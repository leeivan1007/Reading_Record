# Reading_Record

It is my reading with RL, AI papers. There have 7 levels to explain the myself learning on reachers.

There are few class :

1. [Grasping](https://github.com/leeivan1007/Reading_record#Grasping)

2. [Transfering and Muilt-task learning](https://github.com/leeivan1007/Reading_record#transfering_and_muilt-task_learning)

3. [Manipulation](https://github.com/leeivan1007/Reading_record#Manipulation)

4. [Exploration](https://github.com/leeivan1007/Reading_record#Exploration)

5. [Sim2real](https://github.com/leeivan1007/Reading_record#Sim2real)

5. [Others](https://github.com/leeivan1007/Reading_record#Others)

## Grasping

| paper | ~15%  |  ~30%   | ~45%  | ~60%  | ~70%  | ~80%  | ~90%  |
|  ----  |  ----  | ----  | ----  | ----  | ----  | ----  | ----  |
| Deep Reinforcement Learning for Vision-Based Robotic Grasping: A Simulated Comparative Evaluation of Off-Policy Methods  |  ✓  |  ✓  |  ✓  |  ✓  |  ✓  |  ✓  |    |
| Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection  |  ✓  |  ✓  |  ✓  |  ✓  |  ✓  |  ✓  |    |
| A Framework for Efficient Robotic Manipulation  |  ✓  |  ✓  |    |    |    |    |    |
| Grasp Proposal Networks- An End-to-End Solution for Visual Learning of Robotic Grasps  |  ✓  |  ✓  |  ✓  |    |    |    |    |
| QT-Opt Scalable Deep_Reinforcement Learning for Vision-Based Robotic Manipulation  |  ✓  |  ✓  |  ✓  |  ✓  |  ✓  |    |    |
| Dex-Net 2.0: Deep Learning to Plan Robust Grasps withSynthetic Point Clouds and Analytic Grasp Metrics |  ✓  |  ✓  |  ✓  |  ✓  |  ✓  |  ✓  |    |
| Dex-Net 2.1: Learning Deep Policies for Robot Bin Picking by Simulating Robust Grasping Sequences  |  ✓  |  ✓  |  ✓  |  ✓  |    |    |    |
| Dex-Net 3.0: Computing Robust Robot Suction Grasp Targets using a New Analytic Model and Deep Learning  |  ✓  |  ✓  |  ✓  |  ✓  |    |    |    |
|  Combining Deep Deterministic Policy Gradient with Cross-Entropy Method |  ✓  |  ✓  |    |    |    |    |    |

## Transfering and Muilt-task learning

| paper | ~15%  |  ~30%   | ~45%  | ~60%  | ~70%  | ~80%  | ~90%  |
|  ----  |  ----  | ----  | ----  | ----  | ----  | ----  | ----  |
| EPOpt: Learning robust neural network policies..  |  ✓  |  ✓  |    |    |    |    |    |
| Preparing for the Unknown: Learning a Universal Policy with Online System Identification  |  ✓  |    |    |    |    |    |    |
| Sim-to-Real Transfer of Robotic Control with Dynamics Randomization  |  ✓  |    |    |    |    |    |    |
| CAD2RL: Real Single-Image Flight without a Single Real Image  |  ✓  |    |    |    |    |    |    |
| Adapting Visuomotor Representations with Weak Pairwise Constraints  |  ✓  |    |    |    |    |    |    |
| Sing Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping  |  ✓  |    |    |    |    |    |    |
| One-Shot Learning of Manipulation Skills with Online Dynamics Adaptation...  |  ✓  |    |    |    |    |    |    |
|  Distilling the Knowledge in a Neural Network  |    |    |    |    |    |    |    |
|  Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning  |    |    |    |    |    |    |    |
|  Learning Modular Neural Network Policies..  |    |    |    |    |    |    |    |
|  Reinforcement Learning with Deep Energy-Based Policies  |  ✓  |    |    |    |    |    |    |
|  Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping  |    |    |    |    |    |    |    |
|  DARLA: Improving Zero-Shot Transfer in Reinforcement Learning  |  ✓  |    |    |    |    |    |    |
|  Modular Multitask Reinforcement Learning with Policy Sketches  |  ✓  |    |    |    |    |    |    |
|  Stochastic Neural Networks for Hierarchical Reinforcement Learning  |  ✓  |    |    |    |    |    |    |

## Manipulation

| paper | ~15%  |  ~30%   | ~45%  | ~60%  | ~70%  | ~80%  | ~90%  |
|  ----  |  ----  | ----  | ----  | ----  | ----  | ----  | ----  |
| Transporter Networks- Rearranging the Visual World for Robotic Manipulation  |  ✓  |  ✓  |  ✓  |  ✓  |    |    |    |
| Robotic Table Tennis with Model-Free Reinforcement Learning  |  ✓  |  ✓  |    |    |    |    |    |

## Exploration 

| paper | ~15%  |  ~30%   | ~45%  | ~60%  | ~70%  | ~80%  | ~90%  |
|  ----  |  ----  | ----  | ----  | ----  | ----  | ----  | ----  |
| Deep Exploration via Bootstrapped DQN  |  ✓  |  ✓  |  ✓  |    |    |    |    |
| VIME_Variational Information Maximizing Exploration  |  ✓  |  ✓  |    |    |    |    |    |
## Sim2real 

| paper | ~15%  |  ~30%   | ~45%  | ~60%  | ~70%  | ~80%  | ~90%  |
|  ----  |  ----  | ----  | ----  | ----  | ----  | ----  | ----  |
| Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping  |  ✓  |    |     |    |    |    |    |
| 3D Simulation for Robot Arm Control with Deep Q-Learning  |  ✓  |  ✓  | ✓  |    |    |    |    |
## Others 

| paper | ~15%  |  ~30%   | ~45%  | ~60%  | ~70%  | ~80%  | ~90%  |
|  ----  |  ----  | ----  | ----  | ----  | ----  | ----  | ----  |
| Learning to Stop: Dynamic Simulation Monte-Carlo Tree Search  |  ✓  |    |     |    |    |    |    |